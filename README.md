# 不同超参数对CNN的影响

[TOC]

## 项目介绍

本项目旨在探讨超参数对于CNN神经网络的影响，拟探究的超参数为两个，一个是学习速率（learning rate），另一个是训练轮次。

本项目会在[CIFAR-10数据集](https://www.cs.toronto.edu/~kriz/cifar.html)上进行测试，测试指标采用准确率

## 数据集介绍

CIFAR-10数据集是一个大规模（8千万张）小图片数据集的子集。

该数据集共有60000张彩色图像，这些图像大小是32*32，分为10个类，每类6000张图。其中有50000张用于训练，构成了5个训练批次，每一批次10000张图；另外10000用于测试，单独构成一组。测试集的数据里，取自10类中的每一类，每一类随机取1000张。**注意**训练集中的各类图像数量并不一定相同，总体来说，五个训练集之和包含来自每个类的正好5000张图像。

## 超参数

本项目测试的超参数一个是学习速率，其取值集合是[0.1, 0.01, 0.001, 0.0001]；另一个是训练轮次，其取值集合是[5, 10, 15, 20]。其不同取值在每个轮次在训练集的loss情况可见notebook的cell结果。其不同取值在测试集中的准确率如下表所示：

| 训练轮次\学习速率 | 0.1  | 0.01   | 0.001  | 0.0001 |
| :---------------- | ---- | ------ | ------ | ------ |
| 5                 | 10%  | 23.84% | 59.06% | 46.75% |
| 10                | 10%  | 25.15% | 62.51% | 56.28% |
| 15                | 10%  | 24.16% | 61.83% | 62.48% |
| 20                | 10%  | 10%    | 61.41% | 63.5%  |

由上表可以看出，学习速率和训练轮次都对模型的准确率有一定的影响，其中学习速率对模型的影响更大。

学习速率对模型的影响在于影响更新参数时参数的迭代步长。较大的学习速率容易导致迭代步长波动，使得模型不能收敛到全局最小值，因为在梯度下降的过程中，很可能跳过全局最小值，而在最小值附近回荡。较小的学习速率有助于模型收敛到全局最小值，但是会花费更多的时间，因为参数迭代的很慢，必须花费更长的时间来训练神经网络。同时，较小的学习速率也可能使神经网络困在局部极小值。

训练轮次对于模型性能的影响较小，但也是一个关键的超参数。训练轮次不足的情况容易导致模型欠拟合。模型在一定的轮次后会逐渐收敛，所以较大的训练轮次会增加不必要的训练开销。

## 总结

学习速率和训练轮次是影响模型性能重要的两个参数，尤其是学习速率。

对于学习速率算法，可以考虑选择在实验阶段不断查看不同学习速率对模型的影响，从而选择合适的学习速率，也可以从一个较大的学习速率开始，然后慢慢地在训练中降低学习速率。

对于训练轮次，要选择一个合适的轮次，防止不必要的训练开销。

